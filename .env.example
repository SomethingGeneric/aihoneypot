# AI Provider Configuration
# Choose one: llama, openai, mcp
AI_PROVIDER=llama

# LLaMA/Ollama Configuration
LLAMA_ENDPOINT=http://localhost:11434
LLAMA_MODEL=llama3.2

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optional, for custom endpoints

# MCP (Model Context Protocol) Configuration
MCP_SERVER_PATH=/path/to/mcp/server
MCP_SERVER_ARGS=--arg1 value1 --arg2 value2
MCP_TIMEOUT=30